<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: TDD | Razor Sharp Design]]></title>
  <link href="http://rzrsharp.net/blog/categories/tdd/atom.xml" rel="self"/>
  <link href="http://rzrsharp.net/"/>
  <updated>2013-07-25T17:29:55-07:00</updated>
  <id>http://rzrsharp.net/</id>
  <author>
    <name><![CDATA[Justin Reidy]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Testing and Node: Building a Toolset]]></title>
    <link href="http://rzrsharp.net/2013/07/25/testing-and-node-building-a-toolset.html"/>
    <updated>2013-07-25T16:48:00-07:00</updated>
    <id>http://rzrsharp.net/2013/07/25/testing-and-node-building-a-toolset</id>
    <content type="html"><![CDATA[<p><em>This is part two of a series on testing and Node; check out part one,
<a href="/2013/07/16/testing-and-node-why-do-we-test.html">Why do we test</a>.</em></p>

<p>Despite Node.js&rsquo;s relative youth, there&rsquo;s already a  vast ecosystem of tooling
surrounding end-to-end application testing. But the bounteous availability of tools isn&rsquo;t
as positive an aspect as it may appear; many tools lack maturity, while others
have gone beyond the point of maturity to abandonware. Choosing the right
testing toolset when starting a new Node project can be daunting, and can be
enough to discourage you from testing in the first place.</p>

<p>Don&rsquo;t delay. Don&rsquo;t put off. Follow the advice of the excellent
<a href="http://www.growing-object-oriented-software.com/">Growing Object-Oriented Software, Guided by Tests</a>
and set up your test infrastructure
when you first set up your application.</p>

<p>Today, we&rsquo;re going to go step-by-step through creating a new Node app and its accompanying test toolset.
Over the rest of the series, we&rsquo;ll walk through writing a
feature from the outside-in.</p>

<p>Let&rsquo;s get started. Create a new directory for this project; I created one
called <code>testing-and-node</code>. <code>cd</code> in and then <code>npm init</code>. If you haven&rsquo;t used
<code>npm init</code> before, it just asks a series of questions to put together a
<code>package.json</code> file for you. Fill in whatever answers you want, but when the
script asks for the &ldquo;test command&rdquo;, make sure to enter <code>grunt test</code>.</p>

<p>Speaking of which&hellip; you do have <a href="http://gruntjs.com/">Grunt</a> installed, right?
Grunt is a fantastically powerful build tool for JS projects. While some
developers prefer the power and unix-ness of Makefiles, and Rubyists long for
Rake&rsquo;s API, Grunt has a comprehensive ecosystem of tasks that&rsquo;s growing daily.
And since you&rsquo;re coding in JavaScript, you might as well write your build tasks
in JS, too.</p>

<p>If you <em>are</em> new to Grunt, you&rsquo;ll need to install the cli module for use
globally:</p>

<p><code>bash
npm install -g grunt-cli
</code></p>

<p>Next, install a local version of Grunt itself:</p>

<p><code>bash
npm install --save grunt
</code></p>

<p>Great. Grunt relies on the presence of a file called <code>Gruntfile.js</code> to
configure and run builds. Let&rsquo;s set that up now. Open a new Gruntfile.js file
in your editor and enter the following:</p>

<p>```javascript
module.exports = function (grunt) {</p>

<p>  grunt.initConfig({</p>

<p>  });</p>

<p>  grunt.registerTask(&lsquo;test&rsquo;, []); };
```</p>

<p>Go ahead and run <code>npm test</code>. It&rsquo;s green. Hooray! Yes, it&rsquo;s true your tests
don&rsquo;t currently do anything, but now you&rsquo;re free to start setting up the rest
of your toolset. Let&rsquo;s install them in one bunch:</p>

<p><code>bash
npm install --save-dev mocha sinon chai sinon-chai grunt-mocha-test grunt-mocha-webdriver
</code></p>

<p>And if you&rsquo;re a fan of
<a href="http://domenic.me/2012/10/14/youre-missing-the-point-of-promises/">promises</a>,
you might as well install the following right now:</p>

<p><code>bash
npm install --save Q
npm install --save-dev chai-as-promised
</code></p>

<p>We&rsquo;ll also need to install a tool that&rsquo;s not a Node module:
<a href="http://phantomjs.org/">PhantomJS</a>.  You can install it with
<a href="http://brew.sh/">Homebrew</a> if you&rsquo;ve got it; otherwise, there&rsquo;s
<a href="http://phantomjs.org/download.html">binary installers here</a>. If you already have
Phantom installed, just make sure it&rsquo;s on the latest version.</p>

<p>Let&rsquo;s go over the selection of each of these tools. There&rsquo;s certainly other
sets of modules that would work equally well, but this is the toolset with
which I&rsquo;m most familiar, and the one for which I&rsquo;ll advocate.</p>

<h3>mocha <a href="http://visionmedia.github.io/mocha/">http://visionmedia.github.io/mocha/</a></h3>

<p>There&rsquo;s a wide variety of testing frameworks available for Node, from the
extraordinarily comprehensive (<a href="http://pivotal.github.io/jasmine/">Jasmine</a>) to
the extraordinarily minimal (<a href="https://github.com/isaacs/node-tap">node-tap</a>).
Mocha fits neatly in between these two extremes; its one role is to run tests,
and it&rsquo;s agnostic about output, assertion library, and even interface-style
(the only thing Mocha <em>isn&rsquo;t</em> agnostic about is <a href="https://github.com/visionmedia/mocha/pull/329">promise
support</a>). Mocha&rsquo;s best feature
is its ease of async use; supply a test with a callback, and it will be run
asynchronously.</p>

<p>```javascript
describe(&lsquo;a sync test&rsquo;, function () {
  it(&lsquo;is run synchronously&rsquo;, function () {</p>

<pre><code>//assert something synchronous
</code></pre>

<p>  });
});</p>

<p>describe(&lsquo;an async test&rsquo;, function () {
  it(&lsquo;is run asynchronously&rsquo;, function (done) {</p>

<pre><code>//do something async
done(err, result);
</code></pre>

<p>  });
});
```</p>

<h3>sinon <a href="http://sinonjs.org/">http://sinonjs.org/</a></h3>

<p>Since Mocha simply plays the role of test-runner, we need other components to complete our testing
toolset. Sinon is a framework-agnostic library that provides spies, stubs, and
mocks for JavaScript
(<a href="http://martinfowler.com/articles/mocksArentStubs.html#TheDifferenceBetweenMocksAndStubs">Martin Fowler</a>
provides a useful explanation of those terms). Spies, stubs, and mocks are
integral for properly testing the interfaces through which your application
objects communicate; Sinon makes it simple to verify how any function is
called, and can even indicate whether a function has been new-ed.</p>

<h3>chai <a href="http://chaijs.com/">chaijs.com</a></h3>

<p>Completing our main set of testing
tools is chai, a framework-agnostic assertion library. Node provides
<a href="http://nodejs.org/api/assert.html">its own assertion api</a> directly in core, so it&rsquo;s not
strictly necessary to include a third-party assertion module. But Chai provides
a choice of excellent APIs, with error messages that should make the path from
red to green much clearer. I&rsquo;m personally partial to Chai&rsquo;s
<a href="http://chaijs.com/api/bdd/">expect</a> bdd interface. Another benefit of Chai is
that it provides an easy mechanism for adding your own assertion language,
which has led to assertion-plugins like sinon-chai and chai-as-promised.</p>

<h3>sinon-chai <a href="http://chaijs.com/plugins/sinon-chai">http://chaijs.com/plugins/sinon-chai</a></h3>

<p>I&rsquo;m a big believer that cleaner APIs lead to better code; while it&rsquo;s perfectly
acceptable to test Sinon object properties directly, the sinon-chai plugin
makes your tests even clearer. Instead of:</p>

<p><code>javascript
expect(mySpy.calledWith("foo")).to.be.ok;
</code></p>

<p>you can just write:</p>

<p><code>javascript
expect(mySpy).to.have.been.calledWith("foo");
</code></p>

<p>Since you&rsquo;re
going to the trouble of using an expressive assertion library, it makes sense
to make those assertions as clear as possible.</p>

<h3>chai-as-promised <a href="http://chaijs.com/plugins/chai-as-promised">http://chaijs.com/plugins/chai-as-promised</a></h3>

<p>For promise-users, chai-as-promised provides the same benefits as sinon-chai:
more expressive test assertions. Instead of chaining a promise onto the subject
of your test to verify the eventual resolution or rejection, chai-as-promised
allows you to use the same chaining-API as the rest of Chai:</p>

<p><code>javascript
expect(promiseFn({foo: 'bar'})).to.eventually.deep.equal('foobar')
</code></p>

<h3>grunt-mocha-test <a href="https://github.com/pghalliday/grunt-mocha-test">https://github.com/pghalliday/grunt-mocha-test</a></h3>

<p>Because Mocha can be run on both the client and server, there&rsquo;s a surprisingly
large number of Grunt tasks that use the testing framework; I prefer
grunt-mocha-test because of its extreme simplicity. grunt-mocha-test uses the
same options hash as Mocha itself; in fact, all it&rsquo;s doing is firing up processes
with which to run Mocha instances. Of course, running those instances properly,
and catching any weird exceptions, is harder than it sounds &mdash; grunt-mocha-test
has figured out those fringe cases so you don&rsquo;t have to.</p>

<h3>grunt-mocha-webdriver <a href="https://github.com/jmreidy/grunt-mocha-webdriver">https://github.com/jmreidy/grunt-mocha-webdriver</a></h3>

<p>When it comes down to full-stack (aka acceptance or end-to-end) testing, you&rsquo;ll
need a headless browser with which to interact. PhantomJS, which we&rsquo;ll get to
below, provides a headless WebKit browser, but what if you want to run your
acceptance tests against more than just a (fake) instance of WebKit? What if you
want to know if your application will work on mobile browsers, or legacy
versions of IE? That&rsquo;s where <a href="https://saucelabs.com/">SauceLabs</a> comes into
play; it provides an IaaS for testing against any matrix of browsers and
devices.</p>

<p>grunt-mocha-webdriver allows you to write and run Mocha tests as you normally
would, but with one huge benefit &mdash; it automatically inserts a
<a href="https://github.com/admc/wd">WebDriver/Selenium</a> interface into your tests for you. With
grunt-mocha-webdriver, you&rsquo;ll be able to run a single acceptance test against
PhantomJS locally, and then run against a whole suite of browsers on SauceLabs
when you deploy to your CI environment.</p>

<p>If all of that sounds incredibly confusing now, it will make more sense in a
future post in this series.</p>

<h3>PhantomJS <a href="http://phantomjs.org/">http://phantomjs.org/</a></h3>

<p>PhantomJS isn&rsquo;t a Node module; it&rsquo;s a headless WebKit browser. Traditionally,
the interface through which you&rsquo;d interact with Phantom would be a JavaScript
API, and it was notoriously tricky to setup and integrate into the rest of the
testing stack. All that changed with PhantomJS&rsquo;s 1.8 release, which included
<a href="https://github.com/detro/ghostdriver">Ghost Driver</a>,
a pure JavaScript implementation of the WebDriver / Selenium Wire Protocol.
With new versions of PhantomJS, you can run:</p>

<p><code>bash
phantomjs --webdriver=4444
</code></p>

<p>That will keep an instance of Phantom running in the background, against which
you can run your tests via grunt-mocha-webdriver.</p>

<p>This whole process will be explained more in a later post in this series.</p>

<hr>


<br />


<p>And with that, we have a working testing toolset. We&rsquo;re ready to build &mdash; which
we&rsquo;ll start doing in the next post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing and Node: Why Do We Test?]]></title>
    <link href="http://rzrsharp.net/2013/07/16/testing-and-node-why-do-we-test.html"/>
    <updated>2013-07-16T16:30:00-07:00</updated>
    <id>http://rzrsharp.net/2013/07/16/testing-and-node-why-do-we-test</id>
    <content type="html"><![CDATA[<p>Why do we test our code?</p>

<p>The question itself seems sacrilegious in today&rsquo;s developer culture. Admitting
that you aren&rsquo;t building a comprehensive suite of unit and integration tests,
let alone not testing <em>first</em>, amounts to hanging a giant &ldquo;newb&rdquo; sign around
your neck. But sacred cows in any culture can lead to stagnation and a lack of
innovation; if you can&rsquo;t provide good cause for a practice that&rsquo;s demanded of
you, why bother doing it?</p>

<p>I&rsquo;ve worked on a number of different projects, spanning maturity levels,
technologies, and team sizes. While most have employed some degree of testing,
I can&rsquo;t think of a single one that employed what would be considered a &ldquo;robust
test suite&rdquo;. Certainly, open source libraries to which I&rsquo;ve contributed (and
the ones I&rsquo;ve created) have almost all included solid unit test coverage. But
there&rsquo;s a gap between what many product teams and consulting agencies preach
(&ldquo;We test all our code all the time, and only want developers who believe in
testing!&rdquo;) and what they practice (&ldquo;We&rsquo;ve got to get this feature out the door,
forget the tests for now.&rdquo;).</p>

<p>What makes the testing question more complicated is that you can never
fully-automate your way to safety. No matter how comprehensive your tests,
you&rsquo;re going to need a QA team. The most glaring need for QA is the fact that
you can&rsquo;t test the appearance of an app &mdash; and with the rise of the responsive
web, testing appearance (and by extension, usability) becomes even more
important. If you need to spend resources on QA-ing an app anyway, why should
your development team spend extra time writing tests (or testing first) when
they could instead be building features or fixing bugs?</p>

<p>The most compelling answer I&rsquo;ve found to this question comes from Sandi Metz in
her book <a href="http://www.amazon.com/Practical-Object-Oriented-Design-Ruby-Addison-Wesley/dp/0321721330/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1374015857&amp;sr=1-1">Practical Object-Oriented Design in Ruby</a>.
It&rsquo;s probably not surprising that a strong case for testing comes from a
Rubyist; the Ruby community has been loudly preaching test-first Agile
methodologies for years. But Metz articulates ideas in a way that increases
their poignancy. &ldquo;Tests give you confidence to refactor constantly,&rdquo; she
writes. This idea takes the common catchphrase of testing &mdash; &ldquo;red, green,
refactor&rdquo; &mdash; and turns it on its head. Instead of refactoring being a <em>part</em> of
testing, refactoring becomes the <em>point</em> of testing. &ldquo;The true purpose of
testing,&rdquo; Metz argues, &ldquo;is to reduce costs.&rdquo;</p>

<p>As a Node developer, the idea that testing provides you freedom to refactor is
entirely compelling. As I wrote in <a href="http://rzrsharp.net/2013/07/02/private-github-repos-with-npm-and-heroku.html">my article on using private Github
repositories for web application
submodules</a>,
Node developers are constantly on the prowl to refactor common bits of logic
into their own encapsulated components. By test-driving feature development,
you make it significantly easier to break out common modules:</p>

<ol>
<li>Test from the outside in: integration, then unit 2. Implement the feature
(make the tests pass) 3. Isolate code that&rsquo;s useful elsewhere, break it off
into its own module, confirm the tests still pass.</li>
</ol>


<p>In Node-land, &ldquo;red-green-refactor&rdquo; becomes &ldquo;red-green-refactor-publish
[module]&rdquo;.</p>

<p>Further, building proper test coverage may require some additional time from
your development team, but it should also decrease the pressure on your QA team
&mdash; and help everyone involved by reducing coordination costs. Think of a
scenario in which one developer bumps up an application dependency to a newer
version in order to implement a new feature (or fix a bug). The developer
sanity checks the application to see if the new version causes any problems
elsewhere in the app; finding none, the updated dependency is added to the
app&rsquo;s manifest and deployed. A week later, a bug report comes in that&rsquo;s vetted
and validated by a member of the QA team, who then needs to coordinate with
multiple developers to identify the cause of the bug (a regression from the
bumped dependency), fix it, and confirm the fix. The cost of coordinating a fix
to this regression clearly outweighs the cost of writing tests in the first
place, and this scenario is of the sort that automated testing can easily
address. In the Node ecosystem, where we frequently rely on many small
third-party modules, it&rsquo;s especially important to automatically test that our
integration with these modules is always working.</p>

<p>But testing can&rsquo;t reduce costs if we aren&rsquo;t efficient testers. And being an
efficient tester is only partially dependent on your knowledge of good OO
design; it is equally important to have a full and proper understanding of the
tools with which you need to test.</p>

<p>Which brings me to the point of this post. The Node community has a very
effective toolbox for testing first, testing well, and testing comprehensively.
But despite the capabilities of these tools, there&rsquo;s very little discussion on
the web of how to use them. An introduction to Mocha or Jasmine doesn&rsquo;t really
explain how to use them to TDD a Node app, and it certainly doesn&rsquo;t explain how
to integrate these libraries into a continuous-deployment setup with Grunt.</p>

<p>In the next few posts, I&rsquo;ll be stepping through my own &ldquo;best practices&rdquo; for
testing a Node app. I&rsquo;ll be the first to admit that there are probably better
approaches to testing, and I&rsquo;ll be quite happy to receive feedback, but
hopefully this series can serve as a guide to get the Node testing discussion
started. If there&rsquo;s anything you&rsquo;re particularly curious about, please let me
know and I&rsquo;ll try to address it.</p>
]]></content>
  </entry>
  
</feed>
